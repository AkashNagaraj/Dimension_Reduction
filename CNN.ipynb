{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kVuPTGj4Uxcm"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itbcpbkIfDHH",
        "outputId": "1c56d8f5-b77b-463a-e1fe-c326b8ec2029"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "79yi7-uEU28D"
      },
      "outputs": [],
      "source": [
        "class CNN_low_dim(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_low_dim,self).__init__()\n",
        "        self.cnn_layers_low_dim = nn.Sequential(\n",
        "                nn.Conv2d(3,8,kernel_size=3,stride=1,padding=1), # input and output channel\n",
        "                nn.BatchNorm2d(8),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "                nn.Conv2d(8,16,kernel_size=3,stride=1,padding=1),\n",
        "                nn.BatchNorm2d(16),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "                nn.Conv2d(16,32,kernel_size=3,stride=1,padding=1),\n",
        "                nn.BatchNorm2d(32),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "                nn.Conv2d(32,8,kernel_size=3,stride=1,padding=1),\n",
        "                nn.BatchNorm2d(8),\n",
        "                nn.ReLU(inplace=True),\n",
        "                )\n",
        "\n",
        "        self.linear_layers_low_dim = nn.Sequential(\n",
        "                nn.Linear(8,10)\n",
        "                )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.cnn_layers_low_dim(x)\n",
        "        #print(\"Shape after cnn\",x.shape)\n",
        "        x = x.view(x.size(0),-1)\n",
        "        linear_input_shape = x.view(-1,x.shape[-1]).shape[0]\n",
        "        x = self.linear_layers_low_dim(x)\n",
        "        return x\n",
        "\n",
        "class CNN_regular(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_regular,self).__init__()\n",
        "\n",
        "        self.cnn_layers_regular = nn.Sequential(\n",
        "                nn.Conv2d(3,32,kernel_size=3,stride=1,padding=1), # input and output channel\n",
        "                nn.BatchNorm2d(32),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "                nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "                nn.Conv2d(64,128,kernel_size=3,stride=1,padding=1),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "                nn.Conv2d(128,256,kernel_size=3,stride=1,padding=1),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "                nn.Conv2d(256,128,kernel_size=3,stride=1,padding=1),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "                nn.Conv2d(128,64,kernel_size=3,stride=1,padding=1),\n",
        "                nn.BatchNorm2d(64)\n",
        "                )\n",
        "\n",
        "        self.linear_layers_regular = nn.Sequential(\n",
        "            nn.Linear(64,10)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.cnn_layers_regular(x)\n",
        "        x = x.view(x.size(0),-1)\n",
        "        linear_input_shape = x.view(-1,x.shape[-1]).shape[0]\n",
        "        x = self.linear_layers_regular(x)\n",
        "        x = F.log_softmax(x,dim=1)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "K-r3JWwEU8QX"
      },
      "outputs": [],
      "source": [
        "def train(epochs,data_size,reduce_dimensions):\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "    if reduce_dimensions:\n",
        "      new_dimension = 8 # This has to be modified depending on the size of data passed\n",
        "      model = CNN_low_dim().to(device)\n",
        "      X_train = torch.tensor(np.load(\"/content/drive/MyDrive/data/X_PCA_train.npy\")[:data_size,:],dtype=torch.float,requires_grad=True).reshape(-1,3,8,8).to(device)#.reshape(data_size,3,32,32).to(device)\n",
        "      X_test = torch.tensor(np.load(\"/content/drive/MyDrive/data/X_PCA_test.npy\"),dtype=torch.float).reshape(10000,3,8,8).to(device)\n",
        "    else:\n",
        "      model = CNN_regular().to(device)\n",
        "      X_train = torch.tensor(np.load(\"/content/drive/MyDrive/data/X_train.npy\")[:data_size,:],dtype=torch.float,requires_grad=True).reshape(-1,3,32,32).to(device)#.reshape(data_size,3,32,32).to(device)\n",
        "      X_test = torch.tensor(np.load(\"/content/drive/MyDrive/data/X_test.npy\"),dtype=torch.float).reshape(10000,3,32,32).to(device)\n",
        "\n",
        "    train_losses = []\n",
        "\n",
        "    y_train = torch.tensor(np.load(\"/content/drive/MyDrive/data/y_train.npy\")[:data_size],dtype=torch.long).to(device)\n",
        "    y_test = torch.tensor(np.load(\"/content/drive/MyDrive/data/y_test.npy\"),dtype=torch.long).to(device)\n",
        "\n",
        "    print(\"Training shape :\",X_train.shape,y_train.shape)\n",
        "    print(\"Testing shape :\",X_test.shape,y_test.shape)\n",
        "\n",
        "    #print(\"X using cuda : {}, y using cuda:{}\".format(X_train.is_cuda,y_train.is_cuda))\n",
        "    optimizer = optim.Adam(model.parameters(),lr=0.07)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "    batch_size = 1000\n",
        "    for i in range(epochs):\n",
        "      iter = data_size/batch_size\n",
        "      total_loss = 0\n",
        "      for j in range(int(iter)):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_train[j:j+batch_size])\n",
        "        loss = criterion(output,y_train[j:j+batch_size])\n",
        "        total_loss+=loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "      if(i%10==0):\n",
        "        print(\"Loss at {}th iteration is : {}\".format(i,total_loss))\n",
        "      train_losses.append(total_loss)\n",
        "    print(\"The loss during training\",train_losses)\n",
        "\n",
        "\n",
        "    output = model(X_test)\n",
        "    output = torch.argmax(output,dim=1)\n",
        "    print(output.shape,output[:10])\n",
        "    accuracy = sum(torch.eq(output,y_test))/y_test.shape[0]\n",
        "    print(\"The accuracy over 10000 test images is :\",accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-SEOeDLVAa2",
        "outputId": "b3d01b17-d384-47ed-92bb-d8749000e945"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training shape : torch.Size([30000, 3, 32, 32]) torch.Size([30000])\n",
            "Testing shape : torch.Size([10000, 3, 32, 32]) torch.Size([10000])\n",
            "Loss at 0th iteration is : 62.04681169986725\n",
            "Loss at 10th iteration is : 0.0016420066385762766\n",
            "Loss at 20th iteration is : 0.000654751789625152\n",
            "Loss at 30th iteration is : 0.000357604818418622\n",
            "Loss at 40th iteration is : 0.00022432205832956242\n",
            "Loss at 50th iteration is : 0.0001524061167401669\n",
            "Loss at 60th iteration is : 0.00010910482455983583\n",
            "Loss at 70th iteration is : 8.090056439868931e-05\n",
            "Loss at 80th iteration is : 6.165956460790767e-05\n",
            "Loss at 90th iteration is : 4.7959729954527575e-05\n",
            "The loss during training [62.04681169986725, 42.760804533958435, 18.72180213034153, 0.703212327149231, 0.014533358582411893, 0.004578031643177383, 0.0031723601787234657, 0.0025679065147414804, 0.0021683446611859836, 0.0018725460577115882, 0.0016420066385762766, 0.001456689162296243, 0.0013039438454143237, 0.0011758665714296512, 0.0010671636227925774, 0.0009737722357385792, 0.0008927824328566203, 0.0008219021583499853, 0.0007594221788167488, 0.0007040526143100578, 0.000654751789625152, 0.0006105926895543234, 0.0005708742701244773, 0.0005349546772777103, 0.0005023924077249831, 0.00047271357288991567, 0.0004456466467672726, 0.0004208174086670624, 0.00039800900594855193, 0.0003770011617234559, 0.000357604818418622, 0.0003396683541723178, 0.0003230506572435843, 0.00030758756747673033, 0.00029317466123757185, 0.00027971421513939276, 0.0002671573211046052, 0.0002554109023549245, 0.00024437925094389357, 0.00023404387593473075, 0.00022432205832956242, 0.00021518885705518187, 0.00020659006577261607, 0.00019843639756800258, 0.0001907432260850328, 0.00018347607874602545, 0.00017658444403423346, 0.00017004746086968225, 0.00016388369522246649, 0.00015800292840140173, 0.0001524061167401669, 0.00014711494395669433, 0.0001420681501258514, 0.00013725048120249994, 0.00013265488951219595, 0.00012825813155359356, 0.00012410253384587122, 0.00012010977388854371, 0.0001162730613941676, 0.00011261897043368663, 0.00010910482455983583, 0.00010573861436569132, 0.00010250317291138344, 9.940601785274339e-05, 9.642020654609951e-05, 9.356075247524132e-05, 9.08172874005686e-05, 8.820268249110086e-05, 8.56755827953748e-05, 8.322966596097103e-05, 8.090056439868931e-05, 7.863667724450352e-05, 7.647292113688309e-05, 7.437496560669388e-05, 7.236570240820583e-05, 7.041938147267501e-05, 6.853874310763786e-05, 6.672641438854043e-05, 6.498513266706141e-05, 6.330047517622006e-05, 6.165956460790767e-05, 6.008279092384328e-05, 5.8567648693497176e-05, 5.7080518786278844e-05, 5.563129741403827e-05, 5.424728317393601e-05, 5.290785225042782e-05, 5.1607402497211297e-05, 5.035117885654472e-05, 4.914001567613013e-05, 4.7959729954527575e-05, 4.680829101744166e-05, 4.5690470074077894e-05, 4.45986364638884e-05, 4.3551386852414e-05, 4.25447869929485e-05, 4.1558334032743005e-05, 4.059035813952505e-05, 3.966422514167789e-05, 3.8756807043682784e-05]\n",
            "torch.Size([10000]) tensor([9, 0, 1, 6, 1, 6, 0, 5, 6, 8], device='cuda:0')\n",
            "The accuracy over 10000 test images is : tensor(0.4126, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    epochs = 100\n",
        "    data_size = 30000\n",
        "    reduce_dimensions = False\n",
        "    train(epochs,data_size,reduce_dimensions)\n",
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz_igk6HVCTK",
        "outputId": "10544c0c-c222-4a81-a9e4-6f978847c15f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------+------------+\n",
            "|            Modules             | Parameters |\n",
            "+--------------------------------+------------+\n",
            "|  cnn_layers_low_dim.0.weight   |    216     |\n",
            "|   cnn_layers_low_dim.0.bias    |     8      |\n",
            "|  cnn_layers_low_dim.1.weight   |     8      |\n",
            "|   cnn_layers_low_dim.1.bias    |     8      |\n",
            "|  cnn_layers_low_dim.4.weight   |    1152    |\n",
            "|   cnn_layers_low_dim.4.bias    |     16     |\n",
            "|  cnn_layers_low_dim.5.weight   |     16     |\n",
            "|   cnn_layers_low_dim.5.bias    |     16     |\n",
            "|  cnn_layers_low_dim.8.weight   |    4608    |\n",
            "|   cnn_layers_low_dim.8.bias    |     32     |\n",
            "|  cnn_layers_low_dim.9.weight   |     32     |\n",
            "|   cnn_layers_low_dim.9.bias    |     32     |\n",
            "|  cnn_layers_low_dim.12.weight  |    2304    |\n",
            "|   cnn_layers_low_dim.12.bias   |     8      |\n",
            "|  cnn_layers_low_dim.13.weight  |     8      |\n",
            "|   cnn_layers_low_dim.13.bias   |     8      |\n",
            "| linear_layers_low_dim.0.weight |     80     |\n",
            "|  linear_layers_low_dim.0.bias  |     10     |\n",
            "+--------------------------------+------------+\n",
            "Total Trainable Params: 8562\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "8562"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "def count_parameters(model):\n",
        "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
        "    total_params = 0\n",
        "    for name, parameter in model.named_parameters():\n",
        "        if not parameter.requires_grad: continue\n",
        "        param = parameter.numel()\n",
        "        table.add_row([name, param])\n",
        "        total_params+=param\n",
        "    print(table)\n",
        "    print(f\"Total Trainable Params: {total_params}\")\n",
        "    return total_params\n",
        "\n",
        "count_parameters(CNN_low_dim())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gdC6cbZ3X480"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}